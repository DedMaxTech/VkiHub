import asyncio
import io
import os
import re, datetime
import time
import aiofiles
import aiohttp
from bs4 import BeautifulSoup as BS
from config import cfg
import pymupdf
from aiogram import types
from googleapiclient.discovery import build
from urllib.parse import unquote
import camelot,  re

from utils import *
from .types import *

class ConversionBackend(object): # –∫–∞—Å—Ç–æ–º–Ω—ã–π –±–µ–∫–µ–Ω–¥ –¥–ª—è –∫–∞–º–µ–ª–æ—Ç–∞, —É—Å–∫–æ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É —Ä–∞–∑–∞ –≤ 3
    def convert(self, pdf_path, png_path):
        pymupdf.Document(pdf_path)[0].get_pixmap(dpi=120).save(png_path)
        
def parse_schedule_from_pdf(timetable:Timetable):
    '''–ü–∞—Ä—Å–∏–Ω–≥ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –∏–∑ pdf'''
    # —è —É–∂–µ –Ω–µ –ø–æ–º–Ω—é –∫–∞–∫ —Ç—É—Ç –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç.....
    tm = time.perf_counter()
    # !! —á–∞—Å—Ç–æ –Ω—É–∂–Ω–æ –∫–∞–ª–∏–±—Ä–æ–≤–∞—Ç—å —á–∏—Å–ª–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (—Ç–µ—Å—Ç–æ–≤—ã–º –ø—É—Ç—ë–º), —Ç–∫ –º–µ–Ω—è—é—Ç —Ç–æ–ª—â–∏–Ω—É –∏ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –ª–∏–Ω–∏–π –≤ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–∏
    tables = camelot.read_pdf(str(cfg.base_dir/'temp/pdf_files'/(timetable.name+'.pdf')), pages='all',copy_text=['h', 'v'],  line_scale=53, joint_tol=15, line_tol=15, backend=ConversionBackend())
    schedule:dict[str, dict[str, WeekDay]] = {}
    for table in tables:
        data = table.df.values.tolist()
        if '–≤—Ä–µ–º—è' in data[0]: return # —Ç–∞–±–ª–∏—Ü–∞ –ø–µ—Ä–≤–æ–≥–æ —Å–µ–Ω—Ç—è–±—Ä—è
        if len(data[0][2:])!=len(set(data[0][2:])): # –ï—Å–ª–∏ —Ç—ã –Ω–µ –ø–æ–Ω–∏–º–∞–µ—à—å –ø–æ—á–µ–º—É —ç—Ç–∞ –æ—à–∏–±–∫–∞, –æ—Ç–∫—Ä—ã–≤–∞–π –¥–µ–±–∞–≥ –≤—å—é –∫–∞–º–µ–ª–æ—Ç–∞, —Å–∫–æ—Ä–µ–µ –∫—Ä–∏–≤–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –∏ –Ω—É–∂–Ω–æ –º–µ–Ω—è—Ç—å line_scale –≤—ã—à–µ
            raise ConvertingError('–î—É–±–ª–∏–∫–∞—Ç—ã –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ')
        week_dates = {} # –∏—â–µ–º –∏ —É–¥–∞–ª—è–µ–º –¥–∞—Ç—ã —Å —Ä–∞–ø–∏—Å–∞–Ω–∏—è
        last_day = None # –¥–ª—è —Ñ–∏–∫—Å–∞ —Å–∏—Ç—É–∞—Ü–∏–∏ –∫–æ–≥–¥–∞ —É —Ä—è–¥–∞ –Ω–µ—Ç –¥–Ω—è –Ω–µ–¥–µ–ª–∏/—Ü–∏—Ñ—Ä—ã –ø–∞—Ä—ã
        for i in range(1, len(data)):
            if not data[i][0] and not data[i][1] and last_day and any(data[i][j] for j in range(2, len(data[i]))):
                data[i][0] = last_day 
                data[i][1] = str(int(data[i-1][1])+1) # TODO: –ø–∏—Å–∞—Ç—å –Ω–µ —Ü–∏—Ñ—Ä—É –∞ "–≤–Ω–µ –ø–∞—Ä" (—Å–µ–π—á–∞—Å —á–∏—Å–ª–∞ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –≤—Å–µ–≥–æ)
            if data[i][0]:
                last_day = data[i][0]
            for j in range(2, len(data[i])):
                t = re.findall(r'\b\d{2}\.\d{2}\.\d{2}(?:\d{2})?\b', data[i][j])
                if t:
                    week_dates[data[i][0]] = t[0]
                    data[i][j]=''
            if i>1 and data[i][1]==data[i-1][1] and data[i][0]==data[i-1][0]:
                data[i][1] += '.5' # –¥–ª—è –≤—Ç–æ—Ä–æ–π –ø–æ–ª—É–ø–∞—Ä—ã –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–æ–≤–∏–Ω–∫—É, –ø—Ä–æ—Å—Ç–æ —á—Ç–æ–±—ã –ª—é–¥–∏ –Ω–µ –∑–∞–ø—É—Ç–∞–ª–∏—Å—å

        # —Ç—É—Ç —É–∂–µ —Ç—É–ø–æ —Ä–∞—Å–ø–∏—Ö–∏–≤–∞–µ–º –≥–æ—Ç–æ–≤—É—é –∏–Ω—Ñ—É –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
        for i in range(1, len(data)):
            row = data[i]
            for j in range(2, len(row)):
                cont = delete_spaces(row[j].replace('\n', ' '))
                for fr, to in (('—Å–µ–º–∏–Ω–∞—Ä', 'üöå'), ('–ª–µ–∫—Ü–∏—è –¥–∏—Å—Ç–∞–Ω—Ü–∏–æ–Ω–Ω–æ', 'üõè–î–∏—Å—Ç.'),  ('–∞—É–¥.', ''),  # üîç
                                    ('–ø—Ä–æ–∏–∑–≤.–ø—Ä.','üõ†–ü—Ä–∫—Ç'), ('–ª–∞–±.','üî¨'), ('–æ—Ç–º–µ–Ω–∞','')):
                    cont = repl(cont,fr,to)
                cont = delete_spaces(cont)
                cont = re.sub(r'(\b[A-Z–ê-–Ø–Å]{3,}\b(?:\s+\b[A-Z–ê-–Ø–Å]+\b)+)', lambda x: x.group(0).capitalize(), cont)
                
                teacher = re.findall(r'\b[–ê-–Ø–Å][–∞-—è—ë]*\s[–ê-–Ø–Å]\.\s?[–ê-–Ø–Å]\.?\b',row[j]) #\b[–ê-–Ø–Å][–∞-—è—ë]+\s[–ê-–Ø–Å]\.[–ê-–Ø–Å]\.
                classroom = re.findall(r'\b\d{3}[a-z–∞-—è—ë]?\b',row[j])
                schedule.setdefault(data[0][j], {})
                schedule[data[0][j]].setdefault(row[0], WeekDay(weekday=weekdays.index(row[0].title()),date=week_dates.get(row[0], ''),lessons=[]))
                schedule[data[0][j]][row[0]].lessons.append(
                    Lesson(
                        content=cont,
                        number=row[1],
                        group=data[0][j],
                        teacher=teacher[0] if teacher else '',
                        classroom=classroom[0] if classroom else '',
                        co_groups=[data[0][x] for x in range(2, len(row)) if row[j]==row[x]], # and  j!=x and data[0][j][:-1]!=data[0][x][:-1] (–Ω–µ —Å—á–∏—Ç–∞—Ç—å –ø–æ–¥–≥—Ä—É–ø–ø—ã)
                        canceled='–æ—Ç–º–µ–Ω–∞' in row[j].lower(), 
                        raw=row[j]
                    ))

    for gr in schedule: # —É–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –ø–∞—Ä—ã –≤ –∫–æ–Ω—Ü–µ
        for wd in schedule[gr]:
            i = schedule[gr][wd]
            t = []
            flag = False
            for x in reversed(i.lessons):
                if flag or x.content:
                    t.append(x)
                    flag = True
            i.lessons = list(reversed(t))
    logger.debug(f'Parsing time for {timetable.name}: {time.perf_counter()-tm:.2f}')
    timetable.groups = {gr: list(wd.values()) for gr, wd in schedule.items()}

def parse_teachers_timetable(timetables:list[Timetable]):
    '''–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ–ø–æ–¥–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–æ–≥–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è —Å—Ç—É–¥–µ–Ω—Ç–æ–≤'''
    r: dict[str, list['WeekDay']] = {}
    for tt in timetables:
        for gr in tt.groups:
            for wd in tt.groups[gr]:
                for l in wd.lessons:
                    if l.teacher:
                        r.setdefault(l.teacher, [])
                        d = next((i for i in r[l.teacher] if i.weekday==wd.weekday), None)
                        if d is None:
                            d = WeekDay(weekday=wd.weekday, date=wd.date, lessons=[])
                            r[l.teacher].append(d)
                        if not next((i for i in d.lessons if i.number==l.number and i.content==l.content), None):
                            d.lessons.append(l)
    r2 = {}
    for pr in sorted(r):
        for wd in sorted(r[pr], key=lambda x: x.weekday):
            t = {i.number for i in wd.lessons}
            for i in range(1,int(max(t))):
                if str(i) not in t:
                    wd.lessons.append(Lesson('',str(i), '', '', '', [], ''))
            wd.lessons.sort(key=lambda x: x.number)
            r2.setdefault(pr, []).append(wd)  
    return r2

async def get_all_timetables()-> list[Timetable]:
    '''—Å–∫–∞—á–∏–≤–∞–µ—Ç –≤—Å–µ pdf –∫–∏ —Å —Å–∞–π—Ç–∞'''
    if not os.path.exists(cfg.base_dir / 'temp/pdf_files'): os.makedirs(cfg.base_dir / 'temp/pdf_files')
    for i in os.listdir(cfg.base_dir/'temp/pdf_files/'): os.remove(cfg.base_dir/'temp/pdf_files'/i)
    result = []
    async with aiohttp.ClientSession(trust_env=True) as sesion:
        async with sesion.get('https://ci.nsu.ru/education/schedule/', timeout=aiohttp.ClientTimeout(10)) as resp:
            with open(cfg.base_dir/'temp/pagecopy.html', 'w') as file:
                file.write(await resp.text())
            soup = BS(await resp.text(), 'html.parser')
            items = soup.find_all('a', class_='file-link')
            for i in items:
                link = unquote(i.get('href').replace('\n','').strip())
                if '–û—Å–Ω–æ–≤–Ω–æ–µ' in link: continue
                date = re.findall(r'\d\d.\d\d.\d\d', link)[-1] or ''
                tt = Timetable(
                    name=link.split('/')[-1].replace('.pdf','').replace('\n','').replace('–†–∞—Å–ø–∏—Å–∞–Ω–∏–µ','').replace('—Å—Ç—É–¥–µ–Ω—Ç–æ–≤','').replace('–ø—Ä–µ–ø–æ–¥–æ–≤–∞—Ç–µ–ª–µ–π','').replace('–∫—É—Ä—Å–∞','–∫—É—Ä—Å').replace('—Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ ','').replace('09.02.07','–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ').replace('09.02.01','–∂–µ–ª–µ–∑–æ').replace(' –∫–ª–∞—Å—Å–∞','–∫–ª—Å.').replace('–ø–æ—Å–ª–µ ','').replace('–Ω–∞','').replace('–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –∏ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ','–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ').replace('–ö–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –∏ –∫–æ–º–ø–ª–µ–∫—Å—ã','–∂–µ–ª–µ–∑–æ').replace(date,'').replace('  ', ' ').strip(),
                    link=link,
                    date=datetime.datetime(year=int(date.split('.')[2]),month=int(date.split('.')[1]),day=int(date.split('.')[0])),
                    images=[], groups={})
                for i in result:
                    if i.name == tt.name:
                        result.remove(i)
                result.append(tt)
                async with sesion.get('https://ci.nsu.ru'+tt.link if not tt.link.startswith('https://') else tt.link, allow_redirects=True) as r:
                    async with aiofiles.open(cfg.base_dir/'temp/pdf_files'/(tt.name+'.pdf'), 'wb') as file:
                        await file.write(await r.read())
                    doc = pymupdf.Document(cfg.base_dir/'temp/pdf_files'/(tt.name+'.pdf'))
                    for page in doc:
                        tt.text_content += page.get_text()
    # DELETE ME
    # result += [Timetable('1 —Å–ø–æ TEST', '', datetime.datetime(2022, 3, 10), [], {'2401–≤2':[]})]
    return sorted(result, key=lambda x: x.name)


async def pdfs_to_image(bot, tts):
    '''—Ä–µ–Ω–¥–µ—Ä–∏—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç —Ñ–æ—Ç–∫–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è –≤ —Ç–≥'''
    if not os.path.exists(cfg.base_dir / 'temp/images'): os.makedirs(cfg.base_dir / 'temp/images')
    for i in os.listdir(cfg.base_dir/'temp/images'): os.remove(cfg.base_dir/'temp/images'/i)
    for tt in tts:
        for page in pymupdf.Document(cfg.base_dir/'temp/pdf_files'/(tt.name+'.pdf')):
            img = page.get_pixmap(dpi=100).tobytes()
            msg = await bot.send_document(cfg.temp_group if cfg.temp_group else cfg.superuser, types.BufferedInputFile(img, filename=tt.name+'.png'),disable_notification=True)
            tt.images.append(msg.document.file_id)

def get_contacts(creds) -> list[Contact]:
    '''–°–∫–∞—á–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–∞–∫—Ç—ã —Å –∫–∞–±–∏–Ω–µ—Ç–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –≤–∫–∏'''
    service = build('people', 'v1', credentials=creds)
    data = []
    token = None
    while True:
        results = service.people().listDirectoryPeople(
            readMask='names,emailAddresses,phoneNumbers,photos,organizations',
            sources = ['DIRECTORY_SOURCE_TYPE_DOMAIN_CONTACT', 'DIRECTORY_SOURCE_TYPE_DOMAIN_PROFILE'],
            pageSize=1000,
            pageToken=token
        ).execute()
        
        for person in results.get('people', []):
            names = person.get('names', [])
            emails = person.get('emailAddresses', [])
            photos = person.get('photos', [])
            orgs = person.get('organizations', [])
            
            title = (orgs[0].get('title') if orgs else None) or (orgs[0].get('department') if orgs else None) or ''
            is_student = bool(re.match(r'^\d{3,4}[a-z]{1,2}\d$', title))
            
            if is_student:
                title = title.translate(en_to_ru)
            
            c = Contact(
                name=names[0].get('displayName') if names else 'No Name',
                email=emails[0].get('value') if emails else 'No Email',
                photo=photos[0].get('url') if photos else None,
                title=title,
                is_student=is_student
            )
            if 'Unknown' in c.name or c.name.startswith('sum'): continue
            data.append(c)
            
        token = results.get('nextPageToken')
        if not token: break
    return data


